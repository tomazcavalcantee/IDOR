{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomazcavalcantee/IDOR/blob/main/exerc%C3%ADcio_impa_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "64rEpWL2OKYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Preparando os Dados (Já está pronto)\n",
        "digits = load_digits()\n",
        "X = digits.data  # Matriz (1797, 64)\n",
        "y = digits.target # Vetor (1797,)\n",
        "\n",
        "# Normalizando e convertendo para PyTorch\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_tensor = torch.FloatTensor(X)\n",
        "y_tensor = torch.LongTensor(y)\n",
        "\n",
        "# Divisão Treino/Teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "grCFPoP2IMLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo caso queiram explorar os dados:\n",
        "len(digits.target_names) # Isso vai dar 10\n",
        "# ou\n",
        "len(set(digits.target))  # Isso conta os valores únicos (0 a 9), dando 10\n",
        "\n",
        "# # Em digits temos:\n",
        "\n",
        "# 1.  'data' (os dados X)\n",
        "# 2.  'target' (os labels y)\n",
        "# 3.  'frame'\n",
        "# 4.  'feature_names'\n",
        "# 5.  'target_names'\n",
        "# 6.  'images'\n",
        "# 7.  'DESCR' (descrição do dataset)"
      ],
      "metadata": {
        "id": "khXXOUeJJcNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdX53YewIFWe"
      },
      "outputs": [],
      "source": [
        "# SEU TRABALHO COMEÇA AQUI!!!\n",
        "\n",
        "# Complete a arquitetura. Dica: A entrada tem tamanho 64. A saída deve ter tamanho 10 (representando os 10 possíveis números).\n",
        "modelo = nn.Sequential(\n",
        "    nn.Linear(64, 32), # Exemplo de primeira camada\n",
        "    nn.ReLU(),\n",
        "\n",
        "    # Adicione mais camadas aqui, se quiser (p.s: teste assim antes)\n",
        "\n",
        "    # !! ajustar a próxima linha antes de rodar !!\n",
        "    nn.Linear(.., ..)    # Exercício 1-A -> Defina a camada de saída correta. Lembrem-se da análogia do sanduíche, a saída no caso era 1 (sanduíche, nesse caso são 10 possíveis números).\n",
        ")\n",
        "\n",
        "# Função de Loss (aqui que o cálculo entre o output real e o esperado acontece).\n",
        "criterion = nn.CrossEntropyLoss() # Correto para classificação. No exemplo da prática 1, utilizamos o MSE (erro médio quadrático)\n",
        "# Otimizador\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)\n",
        "\n",
        "# Loop de Treino\n",
        "num_epochs = 20000\n",
        "loss_history = []\n",
        "\n",
        "print(\"Iniciando treinamento...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward prop\n",
        "    outputs = modelo(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward prop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_history.append(loss.item())\n",
        "\n",
        "# Plotagem\n",
        "plt.plot(loss_history)\n",
        "plt.title(\"Curva de Aprendizado\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Loss (Erro)\")\n",
        "plt.show()\n",
        "\n",
        "# Teste Final (Cálculo de Acurácia)\n",
        "with torch.no_grad():\n",
        "    outputs = modelo(X_test)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
        "    print(f'Acurácia no Teste: {accuracy*100:.2f}%')\n",
        "\n",
        "# Exercício 1-B -> Olhando para o gráfico, o modelo precisava de todas as 1000 épocas ou ele aprendeu tudo o que podia antes? Em qual época (aproximadamente) ele estabilizou?\n",
        "# Na resposta, anexe a imagem da curva de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.eval() # Colocando o modelo em modo de teste\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = modelo(X_test)\n",
        "    # Pega o índice do maior valor (a classe predita)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Cálculo da Acurácia\n",
        "    total = y_test.size(0)\n",
        "    correct = (predicted == y_test).sum().item()\n",
        "    acc = correct / total\n",
        "    print(f\"\\nAcurácia Final no Teste: {acc*100:.2f}%\")\n",
        "\n",
        "    # Matriz de Confusão (como mostrado nos exemplos de projetos utilizando os dados de EEG)\n",
        "    cm = confusion_matrix(y_test, predicted)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=digits.target_names)\n",
        "    disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
        "    plt.title(\"Matriz de Confusão: Verdadeiro vs Predito\")\n",
        "    plt.show()\n",
        "\n",
        "# Exercício 2 -> O modelo obteve uma acurácia alta. Olhe para a Matriz de Confusão abaixo e localize os números fora da diagonal principal (os erros).\n",
        "\n",
        "# a. Cite um exemplo de erro que aconteceu (Ex: Era o número X, mas o modelo previu Y).\n",
        "\n",
        "# b. Na sua opinião, visualmente (pensando em pixels borrados 8x8), essa confusão faz sentido? (Ex: 3 e 8 se parecem? 1 e 7 se parecem?).\n",
        "\n",
        "# c. Reiniciem o código (colab), mudem a variável num_epochs para um valor bem menor (por exemplo, 10, ou 20). Como ficou a nova matriz de confusão? Faz sentido um modelo menos treinado errar mais?\n",
        "# anexe a imagem da sua matriz de confusão junto do item c."
      ],
      "metadata": {
        "id": "eYPAvFf5MFvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lz1J_gb7OCvw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}